# Finntelligence Engine

**Personalized Loan Offer Engine with Profitability Optimization**

A sophisticated fintech ML system that optimizes loan offers by predicting default probability and customer acceptance rates to maximize profitability.

## Project Status
âœ… **Phase 0: Complete** - Environment and project structure established  
âœ… **Phase 1: Complete** - Data acquisition and exploratory analysis  
âœ… **Phase 2: Complete** - Feature engineering and preprocessing  
âœ… **Phase 3: Complete** - Risk model training and MLflow setup  
âœ… **Phase 4: Complete** - Model registration and explainability  
ğŸš€ **Current**: Migration to GitHub Codespaces  

## Quick Start

### ğŸš€ GitHub Codespaces (Recommended)
[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/huseyincavusbi/t)

1. Click the Codespaces badge above or create a new Codespace from your repository
2. Wait for the environment to set up automatically (2-3 minutes)
3. Run the quick setup: `./setup.sh`
4. Start exploring: `make notebook`

### ğŸ–¥ï¸ Local Development
```bash
# Clone the repository
git clone https://github.com/huseyincaavusbi/t.git
cd t

# Set up environment
make setup

# Quick start
./setup.sh
```

### ğŸ“Š MLflow & Jupyter Access
```bash
make notebook    # Start Jupyter Lab (Port 8888)
make mlflow      # Start MLflow UI (Port 5000)
make help        # Show all available commands
```

## Architecture Overview

This system combines three key components:
1. **Default Risk Model**: Predicts P(Default) for loan applications
2. **Acceptance Model**: Predicts P(Acceptance) given interest rates
3. **Optimization Engine**: Maximizes expected profit per customer

## Project Structure
```
finntelligence-engine/
â”œâ”€â”€ .devcontainer/          # GitHub Codespaces configuration
â”œâ”€â”€ .github/workflows/      # CI/CD pipelines
â”œâ”€â”€ src/                    # Core ML modules
â”‚   â”œâ”€â”€ finntelligence/     # Main package
â”‚   â””â”€â”€ train_risk_model.py # Production training script
â”œâ”€â”€ notebooks/              # Exploratory data analysis
â”œâ”€â”€ data/                   # Data storage (versioned with DVC)
â”œâ”€â”€ tests/                  # Unit and integration tests
â”œâ”€â”€ models/                 # Trained model artifacts
â”œâ”€â”€ configs/                # Configuration files
â”œâ”€â”€ api/                    # FastAPI service endpoints
â”œâ”€â”€ mlruns/                 # MLflow experiment tracking
â”œâ”€â”€ Makefile               # Development commands
â””â”€â”€ requirements.txt       # Python dependencies
```

## Development Workflow

### ğŸ”„ Complete ML Pipeline
```bash
make full-pipeline    # Download data â†’ Process â†’ Train models
```

### ğŸ§ª Individual Steps
```bash
make download-data    # Download Kaggle dataset
make process-data     # Feature engineering
make train-lr         # Train Logistic Regression
make train-xgb        # Train XGBoost
make test            # Run test suite
make lint            # Code quality checks
```

### ğŸ“ˆ Model Tracking & Visualization
- **MLflow UI**: Track experiments, compare models, register artifacts
- **SHAP Explanations**: Understand model decisions and feature importance
- **DVC**: Version control for data and model artifacts

## Data Setup

### Kaggle API Configuration
1. Get your API key from [Kaggle Account Settings](https://www.kaggle.com/account)
2. Create `~/.kaggle/kaggle.json`:
```json
{"username":"your_username","key":"your_api_key"}
```
3. Download data: `make download-data`

### DVC Remote Storage (Optional)
```bash
# Set up cloud storage for data versioning
dvc remote add -d storage s3://your-bucket/path
dvc push  # Upload data to remote
```

## Progress Status

âœ… **Phase 0**: Project Setup & Environment  
âœ… **Phase 1**: Data Acquisition & EDA  
âœ… **Phase 2**: Feature Engineering & Preprocessing  
âœ… **Phase 3**: Risk Model Training & MLflow Setup  
âœ… **Phase 4**: Model Registration & Explainability  
ğŸš€ **Phase 5**: GitHub Codespaces Migration (Current)  
ğŸ”„ **Phase 6**: Acceptance Probability Model (Next)  
ğŸ“‹ **Phase 7**: Profit Optimization Engine  
ğŸŒ **Phase 8**: FastAPI Deployment  
ğŸ”§ **Phase 9**: CI/CD & Production Monitoring  

## ğŸ› ï¸ MLOps Features

- âœ… **Experiment Tracking**: MLflow for model versioning and metrics
- âœ… **Data Versioning**: DVC for reproducible data pipelines  
- âœ… **Model Explainability**: SHAP for interpretable AI
- âœ… **Automated Testing**: pytest for code quality
- âœ… **CI/CD Pipeline**: GitHub Actions for automated deployment
- âœ… **Containerization**: Codespaces for consistent environments
- ğŸ”„ **Model Registry**: Production model management
- ğŸ“‹ **API Deployment**: FastAPI for model serving
- ğŸ“‹ **Monitoring**: Performance and drift detection

## ğŸ“š Documentation

- [Setup Guide](docs/setup.md) - Detailed environment setup
- [Data Guide](docs/data.md) - Dataset documentation  
- [Model Guide](docs/models.md) - Model architecture and training
- [API Guide](docs/api.md) - REST API documentation
- [Deployment Guide](docs/deployment.md) - Production deployment

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make changes and test: `make test`
4. Commit changes: `git commit -m 'Add amazing feature'`
5. Push to branch: `git push origin feature/amazing-feature`
6. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
ğŸ”„ **Phase 5**: Profit Optimization Engine  
ğŸ”„ **Phase 6**: SHAP Explanations  
ğŸ”„ **Phase 7**: FastAPI Service & Deployment  

### Current Capabilities

**Risk Model (Default Prediction)**
- Models: Logistic Regression (baseline), XGBoost (performance)
- Metrics: ROC-AUC, Precision, Recall, F1-Score
- MLflow Integration: Full experiment tracking & model versioning
- Business Analysis: Risk threshold optimization

## Development Principles
- **Reproducibility**: Git + DVC + requirements.txt
- **Modularity**: Clean separation of concerns
- **Explainability**: SHAP integration for model interpretability
- **MLOps Ready**: CI/CD pipeline compatible design

## Quick Start

```bash
# 1. Activate environment
source finnt/bin/activate  # or your activation command

# 2. View MLflow experiments
mlflow ui
# Then open: http://localhost:5000

# 3. Run notebooks in sequence
jupyter notebook notebooks/
```

---
*Generated by Finnt AI Assistant - July 8, 2025*
